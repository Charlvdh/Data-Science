{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main_V2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"o6mK8iC-VK9Z","colab_type":"text"},"source":["# Twitter sentiment analysis model"]},{"cell_type":"markdown","metadata":{"id":"k2mr62blVdT2","colab_type":"text"},"source":["The purpose of this notebook is to develop a sentiment analysis model which will be used by my reputation monitoring application to assist companies in mearninging their reputation quantitatively through the average sentiment expressed by twitter uses in regards to their brand."]},{"cell_type":"markdown","metadata":{"id":"GRs173JlKzkD","colab_type":"text"},"source":["## Notebook setup"]},{"cell_type":"code","metadata":{"id":"Td7hoVXbjNzI","colab_type":"code","outputId":"66fbed4f-b813-442d-80dc-a6e0e5dce568","executionInfo":{"status":"ok","timestamp":1561106410317,"user_tz":-120,"elapsed":1217,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yhrh_uYtK6Ov","colab_type":"code","outputId":"495f7076-93cc-4189-9466-784cdcaa6934","executionInfo":{"status":"ok","timestamp":1561106411823,"user_tz":-120,"elapsed":2691,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## Set the working directory\n","import os\n","if os.getcwd() != \"/content/drive/My Drive/Data Science/Twitter nlp app\":\n","  os.chdir(\"drive/My Drive/Data Science/Twitter nlp app\")\n","print(os.getcwd())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Data Science/Twitter nlp app\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EEkuWSSTLWWX","colab_type":"text"},"source":["## Import libraries and data"]},{"cell_type":"code","metadata":{"id":"evi8ngubLeEf","colab_type":"code","colab":{}},"source":["# Libraries\n","import numpy as np\n","import pandas as pd\n","from string import punctuation\n","from collections import Counter\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IlNKm29iLhAX","colab_type":"code","colab":{}},"source":["# Read in data\n","data = pd.read_csv(\"Data/training.1600000.processed.noemoticon.csv\", encoding='latin-1', header=None, names=[\"sentiment\",\"id\",\"date\",\"query\",\"username\",\"tweet\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YMEbYLyULy1A","colab_type":"text"},"source":["## Data exploration"]},{"cell_type":"code","metadata":{"id":"NX15uwYLL_Fd","colab_type":"code","outputId":"6331dc57-1651-431f-92ea-c65d0b7e811e","executionInfo":{"status":"ok","timestamp":1561106416442,"user_tz":-120,"elapsed":7241,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data.info()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1600000 entries, 0 to 1599999\n","Data columns (total 6 columns):\n","sentiment    1600000 non-null int64\n","id           1600000 non-null int64\n","date         1600000 non-null object\n","query        1600000 non-null object\n","username     1600000 non-null object\n","tweet        1600000 non-null object\n","dtypes: int64(2), object(4)\n","memory usage: 73.2+ MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aqFlt8cIMCcw","colab_type":"code","outputId":"06687dc7-da12-434d-d12d-ea2618d3f459","executionInfo":{"status":"ok","timestamp":1561106416444,"user_tz":-120,"elapsed":7224,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>id</th>\n","      <th>date</th>\n","      <th>query</th>\n","      <th>username</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1467810369</td>\n","      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>_TheSpecialOne_</td>\n","      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1467810672</td>\n","      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>scotthamilton</td>\n","      <td>is upset that he can't update his Facebook by ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1467810917</td>\n","      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>mattycus</td>\n","      <td>@Kenichan I dived many times for the ball. Man...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1467811184</td>\n","      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>ElleCTF</td>\n","      <td>my whole body feels itchy and like its on fire</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1467811193</td>\n","      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n","      <td>NO_QUERY</td>\n","      <td>Karoli</td>\n","      <td>@nationwideclass no, it's not behaving at all....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentiment  ...                                              tweet\n","0          0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n","1          0  ...  is upset that he can't update his Facebook by ...\n","2          0  ...  @Kenichan I dived many times for the ball. Man...\n","3          0  ...    my whole body feels itchy and like its on fire \n","4          0  ...  @nationwideclass no, it's not behaving at all....\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"C1QTikLVMIe5","colab_type":"text"},"source":["## Data cleaning"]},{"cell_type":"code","metadata":{"id":"1d-NV_sROWJP","colab_type":"code","colab":{}},"source":["# Remove unnecessary columns\n","data_dropped = data.drop(columns=[\"id\",\"date\",\"query\",\"username\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVbO79W2OqAZ","colab_type":"code","outputId":"a4225dd8-6883-4124-dc0d-d2b5dfef30f2","executionInfo":{"status":"ok","timestamp":1561106416448,"user_tz":-120,"elapsed":7168,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["data_dropped.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentiment</th>\n","      <th>tweet</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>is upset that he can't update his Facebook by ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>@Kenichan I dived many times for the ball. Man...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>my whole body feels itchy and like its on fire</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>@nationwideclass no, it's not behaving at all....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentiment                                              tweet\n","0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n","1          0  is upset that he can't update his Facebook by ...\n","2          0  @Kenichan I dived many times for the ball. Man...\n","3          0    my whole body feels itchy and like its on fire \n","4          0  @nationwideclass no, it's not behaving at all...."]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"AI3jVNFNOsNQ","colab_type":"code","colab":{}},"source":["# Remove links and usernames\n","link_pat = r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*) ?\"\n","user_pat = r\"@[a-zA-Z0-9_]{1,20} ?\"\n","\n","data_dropped[\"tweet\"] = data_dropped[\"tweet\"].str.replace(link_pat, \"\").str.replace(user_pat, \"\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AtppY0A_RWFX","colab_type":"code","outputId":"b7e0d039-98c9-40ed-d013-5857e973aa80","executionInfo":{"status":"ok","timestamp":1561106419583,"user_tz":-120,"elapsed":10272,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["data_dropped[\"tweet\"].head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    - Awww, that's a bummer.  You shoulda got Davi...\n","1    is upset that he can't update his Facebook by ...\n","2    I dived many times for the ball. Managed to sa...\n","3      my whole body feels itchy and like its on fire \n","4    no, it's not behaving at all. i'm mad. why am ...\n","Name: tweet, dtype: object"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"wQDGKlYnRbN0","colab_type":"code","outputId":"1d677234-ccaf-4f5e-ea4f-ee22accd2ad9","executionInfo":{"status":"ok","timestamp":1561106420603,"user_tz":-120,"elapsed":11269,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Covert to lower case\n","data2 = data_dropped.copy()\n","\n","data2[\"tweet\"] = data2[\"tweet\"].str.lower()\n","\n","data2[\"tweet\"].head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    - awww, that's a bummer.  you shoulda got davi...\n","1    is upset that he can't update his facebook by ...\n","2    i dived many times for the ball. managed to sa...\n","3      my whole body feels itchy and like its on fire \n","4    no, it's not behaving at all. i'm mad. why am ...\n","Name: tweet, dtype: object"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"HrpN-VMwRzTi","colab_type":"code","outputId":"e8c90083-a5ed-48b7-cb33-e985c4527e5a","executionInfo":{"status":"ok","timestamp":1561106423575,"user_tz":-120,"elapsed":14218,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Remove punctuation\n","data3 = data2.copy()\n","\n","data3[\"tweet\"] = data3[\"tweet\"].str.replace('[{}]'.format(string.punctuation), '')\n","\n","data3[\"tweet\"].head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     awww thats a bummer  you shoulda got david ca...\n","1    is upset that he cant update his facebook by t...\n","2    i dived many times for the ball managed to sav...\n","3      my whole body feels itchy and like its on fire \n","4    no its not behaving at all im mad why am i her...\n","Name: tweet, dtype: object"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"mfPrFpLmR_Jk","colab_type":"code","outputId":"a940e86d-c333-4f4f-da43-a6cfc20b4542","executionInfo":{"status":"ok","timestamp":1561106426952,"user_tz":-120,"elapsed":17577,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Remove multiple spaces\n","data4 = data3.copy()\n","\n","data4[\"tweet\"] = data4[\"tweet\"].str.replace(r\" {2,10}\", ' ')\n","\n","data4[\"tweet\"].head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     awww thats a bummer you shoulda got david car...\n","1    is upset that he cant update his facebook by t...\n","2    i dived many times for the ball managed to sav...\n","3      my whole body feels itchy and like its on fire \n","4    no its not behaving at all im mad why am i her...\n","Name: tweet, dtype: object"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"YnHR5MVkSZzE","colab_type":"code","outputId":"8a975128-3fda-4bb1-e074-87cb58191d46","executionInfo":{"status":"ok","timestamp":1561106428414,"user_tz":-120,"elapsed":19020,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Strip leading and trainling spaces\n","data5 = data4.copy()\n","\n","data5[\"tweet\"] = data5[\"tweet\"].str.strip()\n","\n","data5[\"tweet\"].head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    awww thats a bummer you shoulda got david carr...\n","1    is upset that he cant update his facebook by t...\n","2    i dived many times for the ball managed to sav...\n","3       my whole body feels itchy and like its on fire\n","4    no its not behaving at all im mad why am i her...\n","Name: tweet, dtype: object"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"xfJi3HKvS5JY","colab_type":"code","outputId":"4de482f8-50d6-4c4c-d569-3efc56976327","executionInfo":{"status":"ok","timestamp":1561106434856,"user_tz":-120,"elapsed":25443,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Convert each tweet into a list\n","data6 = data5.copy()\n","\n","data6[\"tweet\"] = data6[\"tweet\"].str.split()\n","\n","data6[\"tweet\"].head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    [awww, thats, a, bummer, you, shoulda, got, da...\n","1    [is, upset, that, he, cant, update, his, faceb...\n","2    [i, dived, many, times, for, the, ball, manage...\n","3    [my, whole, body, feels, itchy, and, like, its...\n","4    [no, its, not, behaving, at, all, im, mad, why...\n","Name: tweet, dtype: object"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"5lWcD9iNVSJz","colab_type":"text"},"source":["## Build word_to_int and int_to_word"]},{"cell_type":"code","metadata":{"id":"v3vyHQPmVqTt","colab_type":"code","outputId":"d74ce012-5bc9-4d84-aed7-568eaeba63fb","executionInfo":{"status":"ok","timestamp":1561106439765,"user_tz":-120,"elapsed":30332,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Determine vocab\n","def create_vocab(data):\n","  vocab = []\n","\n","  for tweet in data6[\"tweet\"]:\n","    for word in tweet:\n","      vocab.append(word)\n","  \n","  return list(set(vocab))\n","\n","vocab = create_vocab(data6)\n","\n","len(vocab)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["453852"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"RepeA4IwWXf1","colab_type":"code","colab":{}},"source":["# Map each word in vocab to an int\n","def create_word_to_int_vice_versa(vocab):\n","  \n","  word_to_int = {}\n","  int_to_word = {}\n","  \n","  for i, word in enumerate(vocab):\n","    # Skip 0 as this will be used of for the 'empty' word\n","    word_to_int[word] = i+1\n","    int_to_word[i+1] = word\n","    \n","  return word_to_int, int_to_word\n","\n","word_to_int, int_to_word = create_word_to_int_vice_versa(vocab)\n","\n","w2i = {'word_to_int': word_to_int,\n","       'int_to_word': int_to_word}\n","\n","torch.save(w2i, 'w2i.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ChNsqF3YF81","colab_type":"code","outputId":"2a4f7027-42e7-4b77-b9e2-c271d7552860","executionInfo":{"status":"ok","timestamp":1561106441095,"user_tz":-120,"elapsed":31631,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Test\n","print(word_to_int[\"happy\"])\n","print(int_to_word[390000])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["445499\n","hairhow\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DeH-3vHSWwnd","colab_type":"text"},"source":["## Create matrix representation of dataset"]},{"cell_type":"code","metadata":{"id":"T_HSg0PkYR8D","colab_type":"code","outputId":"a82aa7f7-eed3-46c2-e3dc-e9c3d669174d","executionInfo":{"status":"ok","timestamp":1561106441097,"user_tz":-120,"elapsed":31617,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":714}},"source":["# Determine if some tweets are too long and should be dropped\n","\n","# Compile Series of tweet lengths\n","tweet_lens = data6[\"tweet\"].str.len()\n","\n","# Run value_counts \n","tweet_lens.value_counts().sort_index()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      3124\n","1     15085\n","2     39558\n","3     59779\n","4     79083\n","5     86193\n","6     90471\n","7     90309\n","8     88848\n","9     86238\n","10    82934\n","11    78348\n","12    74291\n","13    69999\n","14    65860\n","15    61851\n","16    58637\n","17    55056\n","18    52994\n","19    51957\n","20    48707\n","21    47548\n","22    45307\n","23    42346\n","24    37713\n","25    31010\n","26    23179\n","27    15397\n","28     9331\n","29     4948\n","30     2353\n","31      994\n","32      370\n","33      121\n","34       42\n","35       10\n","36        4\n","37        2\n","39        2\n","40        1\n","Name: tweet, dtype: int64"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"OaxT_2pVZEYW","colab_type":"code","outputId":"2a334b98-dd90-4599-8228-7bac50c94d30","executionInfo":{"status":"ok","timestamp":1561106442292,"user_tz":-120,"elapsed":32793,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# It looks like we can safely drop any tweets over 30 words\n","\n","# Determine indexes to drop\n","tweet_indices_to_drop = data6[\"tweet\"].loc[tweet_lens > 30].index\n","\n","# Drop these from both train and targets\n","data7 = data6.drop(labels=tweet_indices_to_drop)\n","\n","# Check that it worked as expected\n","data7[\"tweet\"].str.len().max()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"AAVtWSZvZj_V","colab_type":"code","colab":{}},"source":["# Convert tweets to ints and pad\n","def convert_to_ints_and_pad(data, mapping, normal_len=30):\n","  \n","  word_tweets = data\n","  int_tweets = np.zeros((data.shape[0], 30))\n","  \n","  for i, tweet in enumerate(data):\n","    for n, word in enumerate(tweet):\n","      int_tweets[i][n] = mapping[word]\n","  \n","  return np.array(int_tweets)\n","  \n","int_tweets = convert_to_ints_and_pad(data7[\"tweet\"], word_to_int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fRHNfvzoa3g2","colab_type":"code","outputId":"5cce92a8-221a-4335-b9ab-48bd7c9a41a5","executionInfo":{"status":"ok","timestamp":1561106452414,"user_tz":-120,"elapsed":42896,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":[" int_tweets.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1598454, 30)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"TIJYusYHh_ci","colab_type":"text"},"source":["# Convert targets into numpy array with values 0 or 1"]},{"cell_type":"code","metadata":{"id":"_A361-HHiP_1","colab_type":"code","outputId":"24902c45-1d66-432a-b0f2-42d66919c4d9","executionInfo":{"status":"ok","timestamp":1561106452416,"user_tz":-120,"elapsed":42882,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Determine the different values given in the sentiment column\n","data7[\"sentiment\"].value_counts()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4    799611\n","0    798843\n","Name: sentiment, dtype: int64"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"2A4-5cmxiT5k","colab_type":"code","outputId":"bf9a31cf-92ea-488d-870c-17f8a1ffcce9","executionInfo":{"status":"error","timestamp":1561461615290,"user_tz":-120,"elapsed":1463,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["# As per the dataset documentation, a 4 represents positive and a 0, negative\n","# Change this to pos = 1 and neg = 0\n","targets = data7[\"sentiment\"].replace({4:1})\n","\n","targets[:10]"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-592694ced597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentiment\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data7' is not defined"]}]},{"cell_type":"code","metadata":{"id":"JbZGrZJLigjM","colab_type":"code","colab":{}},"source":["# Convert targets to numpy for further processing\n","targets = targets.to_numpy()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BV5V1zsEilx3","colab_type":"code","colab":{}},"source":["# Define function to split dataset into train and val\n","def train_val_split(features, targets, split_frac=0.95):\n","  \"\"\"\n","  Split the data into training and validation sets\n","  \n","  Parameters:\n","  - data -- data to split\n","  - split_frac -- fraction to be train set\n","  \n","  Returns:\n","  - split_dict -- dictionary containing two tuples: (train_x, train_y) and (val_x, val_y)\n","  \"\"\"\n","  \n","  assert features.shape[0] == targets.shape[0]\n","  \n","  split_idx = int(len(targets)*split_frac)\n","  train_x, val_x = features[:split_idx], features[split_idx:]\n","  train_y, val_y = targets[:split_idx], targets[split_idx:]\n","  \n","  return {\"train\": (train_x, train_y), \"val\": (val_x, val_y)}\n","\n","  ## print out the shapes of resulting feature data\n","  print(\"\\t\\t\\tData Shapes:\")\n","  print(\"Train set: \\t\\t{}\".format(train_x.shape), \n","        \"\\nValidation set: \\t{}\".format(val_x.shape))\n","  \n","split_dict = train_val_split(int_tweets, targets)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPnvGwYii8cS","colab_type":"code","outputId":"bf46dd23-2a28-4ada-8be7-b7577df39850","executionInfo":{"status":"ok","timestamp":1561106452428,"user_tz":-120,"elapsed":42857,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Test that it worked\n","train_x, train_y = split_dict[\"train\"]\n","\n","print(train_x.shape)\n","print(train_y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1518531, 30)\n","(1518531,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QcIZe2BLjEUE","colab_type":"text"},"source":["# Dataloaders and batching"]},{"cell_type":"code","metadata":{"id":"RuU4wT51qNcg","colab_type":"code","colab":{}},"source":["# Set batch size\n","batch_size = 50"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GVG_h-vlp66w","colab_type":"code","colab":{}},"source":["train_x, train_y = split_dict[\"train\"]\n","val_x, val_y = split_dict[\"val\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_CuVYX9ip-Zj","colab_type":"code","outputId":"e3ed3bd9-fed1-4e9e-a0ba-869b4ae0ea7a","executionInfo":{"status":"ok","timestamp":1561106452438,"user_tz":-120,"elapsed":42848,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Make sure there are no unfull batches or the model will throw an error\n","number_val_batches = val_y.shape[0]//batch_size\n","number_train_batches = train_y.shape[0]//batch_size\n","\n","val_x, val_y = val_x[0 : batch_size * number_val_batches], val_y[0 : batch_size * number_val_batches]\n","train_x, train_y = train_x[0 : batch_size * number_train_batches], train_y[0 : batch_size * number_train_batches]\n","\n","print(val_x.shape)\n","print(val_y.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(79900, 30)\n","(79900,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dLH2GtMKjAfb","colab_type":"code","colab":{}},"source":["# Create Tensor datasets\n","train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n","valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n","\n","\n","# Shuffle training data\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aHkfJpG7jHkp","colab_type":"code","outputId":"8d5099a2-4429-4eb8-eb39-24a6b4e76e3b","executionInfo":{"status":"ok","timestamp":1561106452445,"user_tz":-120,"elapsed":42833,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["# Obtain one batch of training data and print to test\n","dataiter = iter(train_loader)\n","sample_x, sample_y = dataiter.next()\n","\n","print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n","print('Sample input: \\n', sample_x)\n","print()\n","print('Sample label size: ', sample_y.size()) # batch_size\n","print('Sample label: \\n', sample_y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Sample input size:  torch.Size([50, 30])\n","Sample input: \n"," tensor([[372370., 135750., 336772.,  ...,      0.,      0.,      0.],\n","        [116314., 219362., 122714.,  ...,      0.,      0.,      0.],\n","        [ 18064., 200867., 232944.,  ...,      0.,      0.,      0.],\n","        ...,\n","        [270050., 274154., 154339.,  ...,      0.,      0.,      0.],\n","        [ 26583., 236297.,  26583.,  ...,      0.,      0.,      0.],\n","        [348487., 321412., 288731.,  ...,      0.,      0.,      0.]],\n","       dtype=torch.float64)\n","\n","Sample label size:  torch.Size([50])\n","Sample label: \n"," tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n","        1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n","        1, 0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HIIhxVqPjKMC","colab_type":"text"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"4BS0ad6NjgGe","colab_type":"code","outputId":"f9092849-c7e6-4821-df71-123362602dc8","executionInfo":{"status":"ok","timestamp":1561106452903,"user_tz":-120,"elapsed":43274,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# First checking if GPU is available\n","train_on_gpu=torch.cuda.is_available()\n","\n","if(train_on_gpu):\n","    print('Training on GPU.')\n","else:\n","    print('No GPU available, training on CPU.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training on GPU.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xrkfLTHtjkEv","colab_type":"code","colab":{}},"source":["class SentimentRNN(nn.Module):\n","    \"\"\"\n","    The RNN model that will be used to perform Sentiment analysis.\n","    \"\"\"\n","\n","    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n","        \"\"\"\n","        Initialize the model by setting up the layers.\n","        \"\"\"\n","        super(SentimentRNN, self).__init__()\n","\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","        \n","        # Embedding and LSTM layers\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n","                            dropout=drop_prob, batch_first=True)\n","        \n","        # Dropout layer\n","        self.dropout = nn.Dropout(0.3)\n","        \n","        # Linear and sigmoid layers\n","        self.fc = nn.Linear(hidden_dim, output_size)\n","        self.sig = nn.Sigmoid()\n","        \n","\n","    def forward(self, x, hidden):\n","        \"\"\"\n","        Perform a forward pass of our model on some input and hidden state.\n","        \"\"\"\n","        batch_size = x.size(0)\n","\n","        # Embeddings and lstm_out\n","        x = x.long()\n","        embeds = self.embedding(x)\n","        lstm_out, hidden = self.lstm(embeds, hidden)\n","    \n","        # Stack up lstm outputs\n","        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n","        \n","        # Dropout and fully-connected layer\n","        out = self.dropout(lstm_out)\n","        out = self.fc(out)\n","        # Sigmoid function\n","        sig_out = self.sig(out)\n","        \n","        # Reshape to be batch_size first\n","        sig_out = sig_out.view(batch_size, -1)\n","        sig_out = sig_out[:, -1] # get last batch of labels\n","        \n","        # Return last sigmoid output and hidden state\n","        return sig_out, hidden\n","    \n","    \n","    def init_hidden(self, batch_size):\n","        ''' Initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","        \n","        if (train_on_gpu):\n","            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n","                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n","        else:\n","            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n","                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n","        \n","        return hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHluA0zYjpHH","colab_type":"code","outputId":"3532acc7-99dc-49f1-e0b8-07444bd56d0f","executionInfo":{"status":"ok","timestamp":1561106454864,"user_tz":-120,"elapsed":45217,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# Instantiate the model w/ hyperparams\n","vocab_size = len(word_to_int)+1 # +1 for the 0 padding + word tokens\n","output_size = 1\n","embedding_dim = 400\n","hidden_dim = 256\n","n_layers = 2\n","\n","net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","\n","print(net)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["SentimentRNN(\n","  (embedding): Embedding(453853, 400)\n","  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n","  (dropout): Dropout(p=0.3)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n","  (sig): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z6g8fx0Gj6nj","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"4tPsIf2LjueA","colab_type":"code","colab":{}},"source":["# Learning rate and oss and optimization functions\n","lr=0.0005\n","\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=lr)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5VJ62Bs7j-7q","colab_type":"code","outputId":"6d126b1a-8f50-4a89-a0d0-e20cf455d80d","executionInfo":{"status":"error","timestamp":1561114470507,"user_tz":-120,"elapsed":3255945,"user":{"displayName":"Charl van der Horst","photoUrl":"","userId":"16315115521190499911"}},"colab":{"base_uri":"https://localhost:8080/","height":4761}},"source":["def train(net, train_loader, valid_loader, epochs=1, print_every=100, checkpoint_every = 1000, train_on_gpu=True, clip=5):\n","  \n","  # Initilise counter\n","  counter = 0\n","\n","  # Move model to GPU, if available\n","  if(train_on_gpu):\n","      net.cuda()\n","\n","  net.train()\n","  #Ttrain for some number of epochs\n","  for e in range(epochs):\n","      # initialize hidden state\n","      h = net.init_hidden(batch_size)\n","\n","      # Batch loop\n","      for inputs, labels in train_loader:\n","          counter += 1\n","\n","          if(train_on_gpu):\n","              inputs, labels = inputs.cuda(), labels.cuda()\n","\n","          # Creating new variables for the hidden state, otherwise\n","          # we'd backprop through the entire training history\n","          h = tuple([each.data for each in h])\n","\n","          # Zero accumulated gradients\n","          net.zero_grad()\n","\n","          # Get the output from the model\n","          output, h = net(inputs, h)\n","\n","          # Calculate the loss and perform backprop\n","          loss = criterion(output.squeeze(), labels.float())\n","          loss.backward()\n","          # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","          nn.utils.clip_grad_norm_(net.parameters(), clip)\n","          optimizer.step()\n","          \n","          # Checkpoint model every 'checkpoint_every' steps\n","          if counter % checkpoint_every == 0:\n","            checkpoint = {'vocab_size': len(word_to_int)+1,\n","                'output_size': 1,\n","                'embedding_dim': 400,\n","                'hidden_dim': 256,\n","                'n_layers': 2,\n","                'state_dict': net.state_dict()}\n","\n","            torch.save(checkpoint, 'checkpoint.pth')\n","          \n","\n","          # Loss stats\n","          if counter % print_every == 0:\n","              # Get validation loss\n","              val_h = net.init_hidden(batch_size)\n","              val_losses = []\n","              net.eval()\n","              for inputs, labels in valid_loader:\n","\n","                  # Creating new variables for the hidden state, otherwise\n","                  # we'd backprop through the entire training history\n","                  val_h = tuple([each.data for each in val_h])\n","\n","                  if(train_on_gpu):\n","                      inputs, labels = inputs.cuda(), labels.cuda()\n","\n","                  output, val_h = net(inputs, val_h)\n","                  val_loss = criterion(output.squeeze(), labels.float())\n","\n","                  val_losses.append(val_loss.item())\n","\n","              net.train()\n","              print(\"Epoch: {}/{}\".format(e+1, epochs),\n","                    \"Step: {}\".format(counter),\n","                    \"Loss: {:.6f}\".format(loss.item()),\n","                    \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n","  \n","  return net\n","  \n","train(net, train_loader, valid_loader, epochs=1, print_every=100, train_on_gpu=train_on_gpu, clip=5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 1/1 Step: 100 Loss: 0.379927 Val Loss: 0.468119\n","Epoch: 1/1 Step: 200 Loss: 0.479346 Val Loss: 0.477924\n","Epoch: 1/1 Step: 300 Loss: 0.384448 Val Loss: 0.462696\n","Epoch: 1/1 Step: 400 Loss: 0.419432 Val Loss: 0.468909\n","Epoch: 1/1 Step: 500 Loss: 0.350077 Val Loss: 0.485590\n","Epoch: 1/1 Step: 600 Loss: 0.489647 Val Loss: 0.475267\n","Epoch: 1/1 Step: 700 Loss: 0.486520 Val Loss: 0.488223\n","Epoch: 1/1 Step: 800 Loss: 0.464204 Val Loss: 0.474295\n","Epoch: 1/1 Step: 900 Loss: 0.479766 Val Loss: 0.472518\n","Epoch: 1/1 Step: 1000 Loss: 0.517594 Val Loss: 0.484450\n","Epoch: 1/1 Step: 1100 Loss: 0.323740 Val Loss: 0.481244\n","Epoch: 1/1 Step: 1200 Loss: 0.292436 Val Loss: 0.475642\n","Epoch: 1/1 Step: 1300 Loss: 0.362053 Val Loss: 0.486634\n","Epoch: 1/1 Step: 1400 Loss: 0.464083 Val Loss: 0.476514\n","Epoch: 1/1 Step: 1500 Loss: 0.367959 Val Loss: 0.497679\n","Epoch: 1/1 Step: 1600 Loss: 0.555834 Val Loss: 0.495426\n","Epoch: 1/1 Step: 1700 Loss: 0.340682 Val Loss: 0.511055\n","Epoch: 1/1 Step: 1800 Loss: 0.562142 Val Loss: 0.487623\n","Epoch: 1/1 Step: 1900 Loss: 0.595418 Val Loss: 0.461579\n","Epoch: 1/1 Step: 2000 Loss: 0.314798 Val Loss: 0.478963\n","Epoch: 1/1 Step: 2100 Loss: 0.339413 Val Loss: 0.495412\n","Epoch: 1/1 Step: 2200 Loss: 0.310158 Val Loss: 0.471550\n","Epoch: 1/1 Step: 2300 Loss: 0.402237 Val Loss: 0.483361\n","Epoch: 1/1 Step: 2400 Loss: 0.406055 Val Loss: 0.503912\n","Epoch: 1/1 Step: 2500 Loss: 0.431044 Val Loss: 0.518718\n","Epoch: 1/1 Step: 2600 Loss: 0.457736 Val Loss: 0.492640\n","Epoch: 1/1 Step: 2700 Loss: 0.354040 Val Loss: 0.492281\n","Epoch: 1/1 Step: 2800 Loss: 0.366524 Val Loss: 0.523569\n","Epoch: 1/1 Step: 2900 Loss: 0.313898 Val Loss: 0.477446\n","Epoch: 1/1 Step: 3000 Loss: 0.469035 Val Loss: 0.486330\n","Epoch: 1/1 Step: 3100 Loss: 0.466088 Val Loss: 0.480167\n","Epoch: 1/1 Step: 3200 Loss: 0.352648 Val Loss: 0.493748\n","Epoch: 1/1 Step: 3300 Loss: 0.460261 Val Loss: 0.469853\n","Epoch: 1/1 Step: 3400 Loss: 0.365151 Val Loss: 0.484369\n","Epoch: 1/1 Step: 3500 Loss: 0.384622 Val Loss: 0.491660\n","Epoch: 1/1 Step: 3600 Loss: 0.488709 Val Loss: 0.507784\n","Epoch: 1/1 Step: 3700 Loss: 0.508488 Val Loss: 0.495722\n","Epoch: 1/1 Step: 3800 Loss: 0.436035 Val Loss: 0.501091\n","Epoch: 1/1 Step: 3900 Loss: 0.531260 Val Loss: 0.503103\n","Epoch: 1/1 Step: 4000 Loss: 0.301457 Val Loss: 0.477258\n","Epoch: 1/1 Step: 4100 Loss: 0.364524 Val Loss: 0.496446\n","Epoch: 1/1 Step: 4200 Loss: 0.410547 Val Loss: 0.495033\n","Epoch: 1/1 Step: 4300 Loss: 0.506692 Val Loss: 0.503101\n","Epoch: 1/1 Step: 4400 Loss: 0.303179 Val Loss: 0.503902\n","Epoch: 1/1 Step: 4500 Loss: 0.437916 Val Loss: 0.501945\n","Epoch: 1/1 Step: 4600 Loss: 0.491939 Val Loss: 0.503634\n","Epoch: 1/1 Step: 4700 Loss: 0.590030 Val Loss: 0.496506\n","Epoch: 1/1 Step: 4800 Loss: 0.437058 Val Loss: 0.499840\n","Epoch: 1/1 Step: 4900 Loss: 0.410583 Val Loss: 0.506281\n","Epoch: 1/1 Step: 5000 Loss: 0.486835 Val Loss: 0.489934\n","Epoch: 1/1 Step: 5100 Loss: 0.447830 Val Loss: 0.492671\n","Epoch: 1/1 Step: 5200 Loss: 0.389682 Val Loss: 0.502332\n","Epoch: 1/1 Step: 5300 Loss: 0.330221 Val Loss: 0.522109\n","Epoch: 1/1 Step: 5400 Loss: 0.371246 Val Loss: 0.515818\n","Epoch: 1/1 Step: 5500 Loss: 0.484515 Val Loss: 0.494568\n","Epoch: 1/1 Step: 5600 Loss: 0.417100 Val Loss: 0.518485\n","Epoch: 1/1 Step: 5700 Loss: 0.495685 Val Loss: 0.488019\n","Epoch: 1/1 Step: 5800 Loss: 0.566826 Val Loss: 0.485647\n","Epoch: 1/1 Step: 5900 Loss: 0.440931 Val Loss: 0.486227\n","Epoch: 1/1 Step: 6000 Loss: 0.356844 Val Loss: 0.458280\n","Epoch: 1/1 Step: 6100 Loss: 0.449677 Val Loss: 0.466698\n","Epoch: 1/1 Step: 6200 Loss: 0.487378 Val Loss: 0.504040\n","Epoch: 1/1 Step: 6300 Loss: 0.458408 Val Loss: 0.516509\n","Epoch: 1/1 Step: 6400 Loss: 0.409948 Val Loss: 0.494790\n","Epoch: 1/1 Step: 6500 Loss: 0.531279 Val Loss: 0.489326\n","Epoch: 1/1 Step: 6600 Loss: 0.392609 Val Loss: 0.518159\n","Epoch: 1/1 Step: 6700 Loss: 0.380660 Val Loss: 0.490791\n","Epoch: 1/1 Step: 6800 Loss: 0.340994 Val Loss: 0.472963\n","Epoch: 1/1 Step: 6900 Loss: 0.435456 Val Loss: 0.514616\n","Epoch: 1/1 Step: 7000 Loss: 0.311214 Val Loss: 0.491699\n","Epoch: 1/1 Step: 7100 Loss: 0.326715 Val Loss: 0.483836\n","Epoch: 1/1 Step: 7200 Loss: 0.413222 Val Loss: 0.487521\n","Epoch: 1/1 Step: 7300 Loss: 0.409479 Val Loss: 0.491643\n","Epoch: 1/1 Step: 7400 Loss: 0.359947 Val Loss: 0.496661\n","Epoch: 1/1 Step: 7500 Loss: 0.339358 Val Loss: 0.486032\n","Epoch: 1/1 Step: 7600 Loss: 0.368761 Val Loss: 0.473080\n","Epoch: 1/1 Step: 7700 Loss: 0.352078 Val Loss: 0.484601\n","Epoch: 1/1 Step: 7800 Loss: 0.362234 Val Loss: 0.472501\n","Epoch: 1/1 Step: 7900 Loss: 0.384603 Val Loss: 0.489033\n","Epoch: 1/1 Step: 8000 Loss: 0.471988 Val Loss: 0.477944\n","Epoch: 1/1 Step: 8100 Loss: 0.391906 Val Loss: 0.500728\n","Epoch: 1/1 Step: 8200 Loss: 0.475418 Val Loss: 0.501661\n","Epoch: 1/1 Step: 8300 Loss: 0.398006 Val Loss: 0.486145\n","Epoch: 1/1 Step: 8400 Loss: 0.419970 Val Loss: 0.502054\n","Epoch: 1/1 Step: 8500 Loss: 0.335692 Val Loss: 0.491687\n","Epoch: 1/1 Step: 8600 Loss: 0.394793 Val Loss: 0.511051\n","Epoch: 1/1 Step: 8700 Loss: 0.552731 Val Loss: 0.522916\n","Epoch: 1/1 Step: 8800 Loss: 0.511736 Val Loss: 0.477338\n","Epoch: 1/1 Step: 8900 Loss: 0.455399 Val Loss: 0.485834\n","Epoch: 1/1 Step: 9000 Loss: 0.446714 Val Loss: 0.500463\n","Epoch: 1/1 Step: 9100 Loss: 0.312218 Val Loss: 0.483899\n","Epoch: 1/1 Step: 9200 Loss: 0.380106 Val Loss: 0.489062\n","Epoch: 1/1 Step: 9300 Loss: 0.375483 Val Loss: 0.494315\n","Epoch: 1/1 Step: 9400 Loss: 0.539650 Val Loss: 0.474507\n","Epoch: 1/1 Step: 9500 Loss: 0.347907 Val Loss: 0.480868\n","Epoch: 1/1 Step: 9600 Loss: 0.330452 Val Loss: 0.480079\n","Epoch: 1/1 Step: 9700 Loss: 0.479811 Val Loss: 0.507386\n","Epoch: 1/1 Step: 9800 Loss: 0.308474 Val Loss: 0.468689\n","Epoch: 1/1 Step: 9900 Loss: 0.375571 Val Loss: 0.472056\n","Epoch: 1/1 Step: 10000 Loss: 0.395838 Val Loss: 0.466047\n","Epoch: 1/1 Step: 10100 Loss: 0.317491 Val Loss: 0.463885\n","Epoch: 1/1 Step: 10200 Loss: 0.373818 Val Loss: 0.490283\n","Epoch: 1/1 Step: 10300 Loss: 0.425007 Val Loss: 0.497592\n","Epoch: 1/1 Step: 10400 Loss: 0.367201 Val Loss: 0.485257\n","Epoch: 1/1 Step: 10500 Loss: 0.424069 Val Loss: 0.500724\n","Epoch: 1/1 Step: 10600 Loss: 0.332383 Val Loss: 0.450970\n","Epoch: 1/1 Step: 10700 Loss: 0.372710 Val Loss: 0.471596\n","Epoch: 1/1 Step: 10800 Loss: 0.414116 Val Loss: 0.481415\n","Epoch: 1/1 Step: 10900 Loss: 0.440906 Val Loss: 0.485655\n","Epoch: 1/1 Step: 11000 Loss: 0.326631 Val Loss: 0.476120\n","Epoch: 1/1 Step: 11100 Loss: 0.221386 Val Loss: 0.481245\n","Epoch: 1/1 Step: 11200 Loss: 0.401363 Val Loss: 0.478049\n","Epoch: 1/1 Step: 11300 Loss: 0.308239 Val Loss: 0.494568\n","Epoch: 1/1 Step: 11400 Loss: 0.396856 Val Loss: 0.473034\n","Epoch: 1/1 Step: 11500 Loss: 0.473715 Val Loss: 0.487844\n","Epoch: 1/1 Step: 11600 Loss: 0.493548 Val Loss: 0.480069\n","Epoch: 1/1 Step: 11700 Loss: 0.257707 Val Loss: 0.494892\n","Epoch: 1/1 Step: 11800 Loss: 0.389432 Val Loss: 0.489583\n","Epoch: 1/1 Step: 11900 Loss: 0.422769 Val Loss: 0.479019\n","Epoch: 1/1 Step: 12000 Loss: 0.427715 Val Loss: 0.490661\n","Epoch: 1/1 Step: 12100 Loss: 0.339363 Val Loss: 0.491692\n","Epoch: 1/1 Step: 12200 Loss: 0.426007 Val Loss: 0.511558\n","Epoch: 1/1 Step: 12300 Loss: 0.602344 Val Loss: 0.496467\n","Epoch: 1/1 Step: 12400 Loss: 0.483046 Val Loss: 0.492520\n","Epoch: 1/1 Step: 12500 Loss: 0.341785 Val Loss: 0.468361\n","Epoch: 1/1 Step: 12600 Loss: 0.482333 Val Loss: 0.490518\n","Epoch: 1/1 Step: 12700 Loss: 0.417822 Val Loss: 0.459567\n","Epoch: 1/1 Step: 12800 Loss: 0.350962 Val Loss: 0.506315\n","Epoch: 1/1 Step: 12900 Loss: 0.537002 Val Loss: 0.509850\n","Epoch: 1/1 Step: 13000 Loss: 0.548403 Val Loss: 0.479506\n","Epoch: 1/1 Step: 13100 Loss: 0.489753 Val Loss: 0.495496\n","Epoch: 1/1 Step: 13200 Loss: 0.335465 Val Loss: 0.498108\n","Epoch: 1/1 Step: 13300 Loss: 0.384639 Val Loss: 0.474050\n","Epoch: 1/1 Step: 13400 Loss: 0.369586 Val Loss: 0.490419\n","Epoch: 1/1 Step: 13500 Loss: 0.424384 Val Loss: 0.490108\n","Epoch: 1/1 Step: 13600 Loss: 0.248265 Val Loss: 0.507126\n","Epoch: 1/1 Step: 13700 Loss: 0.559785 Val Loss: 0.473508\n","Epoch: 1/1 Step: 13800 Loss: 0.311957 Val Loss: 0.503191\n","Epoch: 1/1 Step: 13900 Loss: 0.410016 Val Loss: 0.456885\n","Epoch: 1/1 Step: 14000 Loss: 0.465840 Val Loss: 0.491040\n","Epoch: 1/1 Step: 14100 Loss: 0.367221 Val Loss: 0.515154\n","Epoch: 1/1 Step: 14200 Loss: 0.386115 Val Loss: 0.461712\n","Epoch: 1/1 Step: 14300 Loss: 0.373843 Val Loss: 0.467340\n","Epoch: 1/1 Step: 14400 Loss: 0.414307 Val Loss: 0.480573\n","Epoch: 1/1 Step: 14500 Loss: 0.447893 Val Loss: 0.506800\n","Epoch: 1/1 Step: 14600 Loss: 0.445068 Val Loss: 0.476628\n","Epoch: 1/1 Step: 14700 Loss: 0.480926 Val Loss: 0.485320\n","Epoch: 1/1 Step: 14800 Loss: 0.541710 Val Loss: 0.483349\n","Epoch: 1/1 Step: 14900 Loss: 0.471467 Val Loss: 0.475029\n","Epoch: 1/1 Step: 15000 Loss: 0.347645 Val Loss: 0.463607\n","Epoch: 1/1 Step: 15100 Loss: 0.295027 Val Loss: 0.461755\n","Epoch: 1/1 Step: 15200 Loss: 0.415844 Val Loss: 0.472422\n","Epoch: 1/1 Step: 15300 Loss: 0.459990 Val Loss: 0.478196\n","Epoch: 1/1 Step: 15400 Loss: 0.466391 Val Loss: 0.490982\n","Epoch: 1/1 Step: 15500 Loss: 0.536326 Val Loss: 0.484994\n","Epoch: 1/1 Step: 15600 Loss: 0.448614 Val Loss: 0.464995\n","Epoch: 1/1 Step: 15700 Loss: 0.416452 Val Loss: 0.476994\n","Epoch: 1/1 Step: 15800 Loss: 0.414624 Val Loss: 0.486344\n","Epoch: 1/1 Step: 15900 Loss: 0.434403 Val Loss: 0.469063\n","Epoch: 1/1 Step: 16000 Loss: 0.359089 Val Loss: 0.487213\n","Epoch: 1/1 Step: 16100 Loss: 0.387431 Val Loss: 0.496192\n","Epoch: 1/1 Step: 16200 Loss: 0.295562 Val Loss: 0.484368\n","Epoch: 1/1 Step: 16300 Loss: 0.531236 Val Loss: 0.491663\n","Epoch: 1/1 Step: 16400 Loss: 0.426848 Val Loss: 0.467613\n","Epoch: 1/1 Step: 16500 Loss: 0.422236 Val Loss: 0.485381\n","Epoch: 1/1 Step: 16600 Loss: 0.524747 Val Loss: 0.475539\n","Epoch: 1/1 Step: 16700 Loss: 0.375928 Val Loss: 0.473148\n","Epoch: 1/1 Step: 16800 Loss: 0.549052 Val Loss: 0.485918\n","Epoch: 1/1 Step: 16900 Loss: 0.477566 Val Loss: 0.481507\n","Epoch: 1/1 Step: 17000 Loss: 0.353187 Val Loss: 0.485411\n","Epoch: 1/1 Step: 17100 Loss: 0.507806 Val Loss: 0.485259\n","Epoch: 1/1 Step: 17200 Loss: 0.302139 Val Loss: 0.458019\n","Epoch: 1/1 Step: 17300 Loss: 0.317246 Val Loss: 0.480748\n","Epoch: 1/1 Step: 17400 Loss: 0.313448 Val Loss: 0.465272\n","Epoch: 1/1 Step: 17500 Loss: 0.506244 Val Loss: 0.488073\n","Epoch: 1/1 Step: 17600 Loss: 0.389289 Val Loss: 0.483973\n","Epoch: 1/1 Step: 17700 Loss: 0.506199 Val Loss: 0.491097\n","Epoch: 1/1 Step: 17800 Loss: 0.280358 Val Loss: 0.477320\n","Epoch: 1/1 Step: 17900 Loss: 0.388806 Val Loss: 0.476140\n","Epoch: 1/1 Step: 18000 Loss: 0.325316 Val Loss: 0.471743\n","Epoch: 1/1 Step: 18100 Loss: 0.504409 Val Loss: 0.481400\n","Epoch: 1/1 Step: 18200 Loss: 0.375998 Val Loss: 0.475135\n","Epoch: 1/1 Step: 18300 Loss: 0.442166 Val Loss: 0.488034\n","Epoch: 1/1 Step: 18400 Loss: 0.421880 Val Loss: 0.487135\n","Epoch: 1/1 Step: 18500 Loss: 0.608631 Val Loss: 0.470754\n","Epoch: 1/1 Step: 18600 Loss: 0.373987 Val Loss: 0.474047\n","Epoch: 1/1 Step: 18700 Loss: 0.569539 Val Loss: 0.460829\n","Epoch: 1/1 Step: 18800 Loss: 0.483274 Val Loss: 0.476269\n","Epoch: 1/1 Step: 18900 Loss: 0.571788 Val Loss: 0.449276\n","Epoch: 1/1 Step: 19000 Loss: 0.409129 Val Loss: 0.501600\n","Epoch: 1/1 Step: 19100 Loss: 0.439484 Val Loss: 0.497925\n","Epoch: 1/1 Step: 19200 Loss: 0.422435 Val Loss: 0.484282\n","Epoch: 1/1 Step: 19300 Loss: 0.319270 Val Loss: 0.473485\n","Epoch: 1/1 Step: 19400 Loss: 0.413827 Val Loss: 0.480838\n","Epoch: 1/1 Step: 19500 Loss: 0.450954 Val Loss: 0.466623\n","Epoch: 1/1 Step: 19600 Loss: 0.461088 Val Loss: 0.501713\n","Epoch: 1/1 Step: 19700 Loss: 0.361509 Val Loss: 0.470037\n","Epoch: 1/1 Step: 19800 Loss: 0.329886 Val Loss: 0.475248\n","Epoch: 1/1 Step: 19900 Loss: 0.442118 Val Loss: 0.496126\n","Epoch: 1/1 Step: 20000 Loss: 0.370232 Val Loss: 0.450507\n","Epoch: 1/1 Step: 20100 Loss: 0.409061 Val Loss: 0.476330\n","Epoch: 1/1 Step: 20200 Loss: 0.494595 Val Loss: 0.522341\n","Epoch: 1/1 Step: 20300 Loss: 0.307018 Val Loss: 0.465475\n","Epoch: 1/1 Step: 20400 Loss: 0.426102 Val Loss: 0.492198\n","Epoch: 1/1 Step: 20500 Loss: 0.471886 Val Loss: 0.453976\n","Epoch: 1/1 Step: 20600 Loss: 0.567480 Val Loss: 0.491768\n","Epoch: 1/1 Step: 20700 Loss: 0.341596 Val Loss: 0.498210\n","Epoch: 1/1 Step: 20800 Loss: 0.428134 Val Loss: 0.468765\n","Epoch: 1/1 Step: 20900 Loss: 0.425332 Val Loss: 0.466494\n","Epoch: 1/1 Step: 21000 Loss: 0.338784 Val Loss: 0.486633\n","Epoch: 1/1 Step: 21100 Loss: 0.356116 Val Loss: 0.449786\n","Epoch: 1/1 Step: 21200 Loss: 0.470314 Val Loss: 0.489586\n","Epoch: 1/1 Step: 21300 Loss: 0.509219 Val Loss: 0.493691\n","Epoch: 1/1 Step: 21400 Loss: 0.483880 Val Loss: 0.470488\n","Epoch: 1/1 Step: 21500 Loss: 0.416473 Val Loss: 0.483336\n","Epoch: 1/1 Step: 21600 Loss: 0.368885 Val Loss: 0.493866\n","Epoch: 1/1 Step: 21700 Loss: 0.315687 Val Loss: 0.512032\n","Epoch: 1/1 Step: 21800 Loss: 0.386474 Val Loss: 0.485699\n","Epoch: 1/1 Step: 21900 Loss: 0.282327 Val Loss: 0.480091\n","Epoch: 1/1 Step: 22000 Loss: 0.356923 Val Loss: 0.459708\n","Epoch: 1/1 Step: 22100 Loss: 0.318447 Val Loss: 0.479379\n","Epoch: 1/1 Step: 22200 Loss: 0.332312 Val Loss: 0.472567\n","Epoch: 1/1 Step: 22300 Loss: 0.556898 Val Loss: 0.478572\n","Epoch: 1/1 Step: 22400 Loss: 0.278773 Val Loss: 0.452293\n","Epoch: 1/1 Step: 22500 Loss: 0.320433 Val Loss: 0.499197\n","Epoch: 1/1 Step: 22600 Loss: 0.483992 Val Loss: 0.454343\n","Epoch: 1/1 Step: 22700 Loss: 0.440855 Val Loss: 0.454673\n","Epoch: 1/1 Step: 22800 Loss: 0.489252 Val Loss: 0.487733\n","Epoch: 1/1 Step: 22900 Loss: 0.481860 Val Loss: 0.482433\n","Epoch: 1/1 Step: 23000 Loss: 0.374521 Val Loss: 0.481712\n","Epoch: 1/1 Step: 23100 Loss: 0.281576 Val Loss: 0.487428\n","Epoch: 1/1 Step: 23200 Loss: 0.409474 Val Loss: 0.497061\n","Epoch: 1/1 Step: 23300 Loss: 0.424741 Val Loss: 0.484953\n","Epoch: 1/1 Step: 23400 Loss: 0.588571 Val Loss: 0.490788\n","Epoch: 1/1 Step: 23500 Loss: 0.346183 Val Loss: 0.456133\n","Epoch: 1/1 Step: 23600 Loss: 0.468550 Val Loss: 0.494625\n","Epoch: 1/1 Step: 23700 Loss: 0.669705 Val Loss: 0.476802\n","Epoch: 1/1 Step: 23800 Loss: 0.439012 Val Loss: 0.465972\n","Epoch: 1/1 Step: 23900 Loss: 0.456379 Val Loss: 0.479008\n","Epoch: 1/1 Step: 24000 Loss: 0.316305 Val Loss: 0.470480\n","Epoch: 1/1 Step: 24100 Loss: 0.388382 Val Loss: 0.480637\n","Epoch: 1/1 Step: 24200 Loss: 0.370991 Val Loss: 0.485099\n","Epoch: 1/1 Step: 24300 Loss: 0.390883 Val Loss: 0.508268\n","Epoch: 1/1 Step: 24400 Loss: 0.471067 Val Loss: 0.499519\n","Epoch: 1/1 Step: 24500 Loss: 0.384208 Val Loss: 0.480407\n","Epoch: 1/1 Step: 24600 Loss: 0.420489 Val Loss: 0.482817\n","Epoch: 1/1 Step: 24700 Loss: 0.272787 Val Loss: 0.477277\n","Epoch: 1/1 Step: 24800 Loss: 0.351560 Val Loss: 0.469270\n","Epoch: 1/1 Step: 24900 Loss: 0.558203 Val Loss: 0.473936\n","Epoch: 1/1 Step: 25000 Loss: 0.617263 Val Loss: 0.466318\n","Epoch: 1/1 Step: 25100 Loss: 0.442414 Val Loss: 0.464373\n","Epoch: 1/1 Step: 25200 Loss: 0.340084 Val Loss: 0.478197\n","Epoch: 1/1 Step: 25300 Loss: 0.504898 Val Loss: 0.464797\n","Epoch: 1/1 Step: 25400 Loss: 0.361193 Val Loss: 0.487498\n","Epoch: 1/1 Step: 25500 Loss: 0.397394 Val Loss: 0.477579\n","Epoch: 1/1 Step: 25600 Loss: 0.323983 Val Loss: 0.467993\n","Epoch: 1/1 Step: 25700 Loss: 0.308667 Val Loss: 0.482167\n","Epoch: 1/1 Step: 25800 Loss: 0.493973 Val Loss: 0.478425\n","Epoch: 1/1 Step: 25900 Loss: 0.533629 Val Loss: 0.458532\n","Epoch: 1/1 Step: 26000 Loss: 0.488456 Val Loss: 0.461555\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-d0b81d739287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-61-d0b81d739287>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, valid_loader, epochs, print_every, checkpoint_every, train_on_gpu, clip)\u001b[0m\n\u001b[1;32m     40\u001b[0m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0;31m# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m           \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mparam_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtotal_norm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mparam_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_norm\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclip_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_norm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"3v9_krFJaixe","colab_type":"text"},"source":["## Testing"]},{"cell_type":"code","metadata":{"id":"pwEgo09FZVoK","colab_type":"code","colab":{}},"source":["# Create function to load chackpoints\n","def load_checkpoint(filepath):\n","    checkpoint = torch.load(filepath)\n","    \n","    vocab_size = checkpoint['vocab_size']\n","    output_size = checkpoint['output_size']\n","    embedding_dim = checkpoint['embedding_dim']\n","    hidden_dim = checkpoint['hidden_dim']\n","    n_layers = checkpoint['n_layers']\n","    \n","    model = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n","    model.load_state_dict(checkpoint['state_dict'])\n","    \n","    print(\"--Checkpoint loaded--\")\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bA_HFkKyyPTJ","colab_type":"code","colab":{}},"source":["# Get test data loss and accuracy\n","\n","loaded_net = load_checkpoint('checkpoint.pth').cuda()\n","\n","test_loader = valid_loader\n","\n","test_losses = [] # track loss\n","num_correct = 0\n","\n","# Init hidden state\n","h = loaded_net.init_hidden(batch_size)\n","\n","loaded_net.eval()\n","# Iterate over test data\n","for inputs, labels in test_loader:\n","\n","    # Creating new variables for the hidden state, otherwise\n","    # we'd backprop through the entire training history\n","    h = tuple([each.data for each in h])\n","\n","    if(train_on_gpu):\n","        inputs, labels = inputs.cuda(), labels.cuda()\n","    \n","    # Get predicted outputs\n","    output, h = loaded_net(inputs, h)\n","    \n","    # Calculate loss\n","    test_loss = criterion(output.squeeze(), labels.float())\n","    test_losses.append(test_loss.item())\n","    \n","    # Convert output probabilities to predicted class (0 or 1)\n","    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n","    \n","    # Compare predictions to true label\n","    correct_tensor = pred.eq(labels.float().view_as(pred))\n","    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","    num_correct += np.sum(correct)\n","\n","\n","loaded_net.train()\n","\n","# -- stats! -- ##\n","# avg test loss\n","print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n","\n","# accuracy over all test data\n","test_acc = num_correct/len(test_loader.dataset)\n","print(\"Test accuracy: {:.3f}\".format(test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gSUejOcQIOEW","colab_type":"code","colab":{}},"source":["test_review_neg = \"If I have to work here for one more day I'm going to shoot myself\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvL6VGXt1XLj","colab_type":"code","colab":{}},"source":["def tokenize_review(test_review):\n","    test_review = test_review.lower() # lowercase\n","    # Get rid of punctuation\n","    test_text = ''.join([c for c in test_review if c not in punctuation])\n","\n","    #Ssplitting by spaces\n","    test_words = test_text.split()\n","\n","    # Tokens\n","    test_ints = []\n","    test_ints.append([word_to_int[word] for word in test_words])\n","\n","    return test_ints[0]\n","\n","# Test code and generate tokenized review\n","test_ints = tokenize_review(test_review_neg)\n","print(test_ints)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGLq78f7Gg3D","colab_type":"code","colab":{}},"source":["# Test sequence padding\n","def pad_features(test_ints, seq_length):\n","  features = [0 for i in range(seq_length)]\n","  \n","  for i in range(len(test_ints)):\n","    features[i] = test_ints[i]\n","  \n","  return np.array([features])\n","\n","seq_length=30 \n","features = pad_features(test_ints, seq_length)\n","\n","print(features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fr179SuTGhG1","colab_type":"code","colab":{}},"source":["# Test conversion to tensor and pass into model\n","feature_tensor = torch.from_numpy(features)\n","print(feature_tensor.size())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G_8A2la2GhPc","colab_type":"code","colab":{}},"source":["def predict(net, test_review, sequence_length=200):\n","    \n","    net.eval()\n","    \n","    # Tokenize review\n","    test_ints = tokenize_review(test_review)\n","    \n","    # Pad tokenized sequence\n","    seq_length=sequence_length\n","    features = pad_features(test_ints, seq_length)\n","    \n","    # Convert to tensor to pass into model\n","    feature_tensor = torch.from_numpy(features)\n","    \n","    batch_size = feature_tensor.size(0)\n","    \n","    # Initialize hidden state\n","    h = net.init_hidden(batch_size)\n","    \n","    if(train_on_gpu):\n","        feature_tensor = feature_tensor.cuda()\n","    \n","    # Get the output from the model\n","    output, h = net(feature_tensor, h)\n","    \n","    # Convert output probabilities to predicted class (0 or 1)\n","    pred = torch.round(output.squeeze()) \n","    # Printing output value, before rounding\n","    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n","    \n","    # Print custom response\n","    if(pred.item()==1):\n","        print(\"Positive tweet detected!\")\n","    else:\n","        print(\"Negative tweet detected.\")\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssgSh_wSGhW_","colab_type":"code","colab":{}},"source":["# Call function\n","seq_length = 30 \n","\n","predict(loaded_net, test_review_neg, seq_length)"],"execution_count":0,"outputs":[]}]}